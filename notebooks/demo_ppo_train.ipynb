{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ssCOanHc8JH_"
      },
      "source": [
        "## Demo for step-by-step training with PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sOmCoOrF0F8"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import functools\n",
        "import os\n",
        "from os import getcwd\n",
        "from os.path import join\n",
        "from IPython.display import HTML, clear_output\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "  import brax\n",
        "except ImportError:\n",
        "  !pip install git+https://github.com/google/brax.git@main\n",
        "  clear_output()\n",
        "  import brax\n",
        "\n",
        "from brax import envs\n",
        "from brax import jumpy as jp\n",
        "from brax.io import html\n",
        "from brax.io import model\n",
        "from brax.training.agents.ppo import train as ppo\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  from jax.tools import colab_tpu\n",
        "  colab_tpu.setup_tpu()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm8zbPBcJ5RJ"
      },
      "source": [
        "#### Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "NaJDZqhCLovU",
        "outputId": "50994b20-d788-4264-af00-a3f06d58f943"
      },
      "outputs": [],
      "source": [
        "SEED = 0\n",
        "env_name = \"grasp\"\n",
        "env = envs.get_environment(env_name=env_name)\n",
        "state = env.reset(rng=jp.random_prngkey(seed=SEED))\n",
        "\n",
        "HTML(html.render(env.sys, [state.qp]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_ppo(num_timesteps, env_name):\n",
        "\tprint(f\"Training PPO for '{num_timesteps}' timesteps'\")\n",
        "\n",
        "\tenv = envs.get_environment(env_name=env_name)\n",
        "\tstate = env.reset(rng=jp.random_prngkey(seed=SEED))\n",
        "\n",
        "\ttrain_fn = functools.partial(ppo.train, num_timesteps=num_timesteps, num_evals=10, reward_scaling=10, episode_length=1000, normalize_observations=True, action_repeat=1, unroll_length=20, num_minibatches=32, num_updates_per_batch=2, discounting=0.99, learning_rate=3e-4, entropy_cost=0.001, num_envs=2048, batch_size=256)\n",
        "\n",
        "\tmax_y = 100\n",
        "\tmin_y = 0\n",
        "\n",
        "\txdata, ydata = [], []\n",
        "\ttimes = [datetime.now()]\n",
        "\n",
        "\tdef progress(num_steps, metrics):\n",
        "\t\ttimes.append(datetime.now())\n",
        "\t\txdata.append(num_steps)\n",
        "\t\tydata.append(metrics['eval/episode_reward'])\n",
        "\t\tclear_output(wait=True)\n",
        "\t\t# plt.xlim([0, train_fn.keywords['num_timesteps']])\n",
        "\t\t# plt.ylim([min_y, max_y])\n",
        "\t\t# plt.xlabel('# environment steps')\n",
        "\t\t# plt.ylabel('reward per episode')\n",
        "\t\t# plt.plot(xdata, ydata)\n",
        "\t\t# plt.show()\n",
        "\n",
        "\tmake_inference_fn, params, _ = train_fn(environment=env, progress_fn=progress)\n",
        "\tprint(f'time to jit: {times[1] - times[0]}')\n",
        "\tprint(f'time to train: {times[-1] - times[1]}')\n",
        "\n",
        "\treturn make_inference_fn, params, times, xdata, ydata\n",
        "\n",
        "def visual_rollout(inference_fn, env_name, steps=100, seed=0):\n",
        "\tenv = envs.create(env_name=env_name)\n",
        "\tjit_env_reset = jax.jit(env.reset)\n",
        "\tjit_env_step = jax.jit(env.step)\n",
        "\tjit_inference_fn = jax.jit(inference_fn)\n",
        "\n",
        "\trollout = []\n",
        "\trng = jax.random.PRNGKey(seed=seed)\n",
        "\tstate = jit_env_reset(rng=rng)\n",
        "\tfor _ in range(steps):\n",
        "\t\trollout.append(state)\n",
        "\t\tact_rng, rng = jax.random.split(rng)\n",
        "\t\tact, _ = jit_inference_fn(state.obs, act_rng)\n",
        "\t\tstate = jit_env_step(state, act)\n",
        "\n",
        "\treturn env.sys, [s.qp for s in rollout]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Training (step-by-step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_num_timesteps = [1_000, 5_000_000, 400_000_000]\n",
        "\n",
        "inference_fns = []\n",
        "\n",
        "for idx, num_timesteps in enumerate(training_num_timesteps):\n",
        "\tmake_inference_fn, params, times, xdata, ydata = train_ppo(num_timesteps, env_name)\n",
        "\tinference_fns.append(make_inference_fn(params))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Visualise learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vis_steps = [300, 500, 750]\n",
        "\n",
        "env_sys = []\n",
        "rollouts = []\n",
        "\n",
        "for idx, inference_fn in enumerate(inference_fns):\n",
        "\tsys, rollout = visual_rollout(inference_fn, env_name, steps=vis_steps[idx], seed=SEED)\n",
        "\tenv_sys.append(sys)\n",
        "\trollouts.append(rollout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, sys in enumerate(env_sys):\n",
        "\tHTML(html.render(sys, rollouts[i]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Brax Training.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "reinforcement_learning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "b329387e251b95764b8f65684563519503b45dc8027da482b0a7bdbaa4a30d3e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
